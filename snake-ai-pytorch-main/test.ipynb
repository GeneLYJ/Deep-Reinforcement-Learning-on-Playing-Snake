{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.8.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from game import SnakeGameAI, Direction, Point\n",
    "from model import Linear_QNet, QTrainer\n",
    "from helper import plot\n",
    "import pygame\n",
    "\n",
    "\n",
    "import math, random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import keyboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "game = SnakeGameAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "move = [1,1,1]\n",
    "reward, game_over, score, array3D = game.play_step(move)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN THIS IF YOU WANT TO UNDERSTAND ONLY\n",
    "game = SnakeGameAI()\n",
    "move = [0,0,0]\n",
    "while True:\n",
    "  \n",
    "    reward, game_over, score,array3D = game.play_step(move)\n",
    "\n",
    "    time.sleep(1)\n",
    "    if game_over == True:\n",
    "        break\n",
    "\n",
    "print('Final Score', score)\n",
    "pygame.display.quit() \n",
    "pygame.quit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 120, 3)\n",
      "(120, 180, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20a5b99a6a0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "array3D\n",
    "print(array3D.shape)\n",
    "\n",
    "v = array3D.transpose((1,0,2))\n",
    "print(v.shape)\n",
    "\n",
    "plt.imshow(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS ONLY IF YOU WANT TO CLOSE THE PYGAME WINDOW\n",
    "pygame.display.quit() \n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class ReplayBuffer(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "    \n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        state      = np.expand_dims(state, 0)\n",
    "        next_state = np.expand_dims(next_state, 0)\n",
    "            \n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        state, action, reward, next_state, done = zip(*random.sample(self.buffer, batch_size))\n",
    "        return np.concatenate(state), action, reward, np.concatenate(next_state), done\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_td_loss(batch_size):\n",
    "    state, action, reward, next_state, done = replay_buffer.sample(batch_size)\n",
    "\n",
    "    #state      = Variable(torch.FloatTensor(np.float32(state)))\n",
    "    #next_state = Variable(torch.FloatTensor(np.float32(next_state)), volatile=True)\n",
    "    #action     = Variable(torch.LongTensor(action))\n",
    "    #reward     = Variable(torch.FloatTensor(reward))\n",
    "    #done       = Variable(torch.FloatTensor(done))\n",
    "\n",
    "    q_values      = model(state)\n",
    "    next_q_values = model(next_state)\n",
    "\n",
    "    q_value          = q_values.gather(1, action.unsqueeze(1)).squeeze(1)\n",
    "    next_q_value     = next_q_values.max(1)[0]\n",
    "    expected_q_value = reward + gamma * next_q_value * (1 - done)\n",
    "    \n",
    "    loss = (q_value - Variable(expected_q_value.data)).pow(2).mean()\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnDQN(nn.Module):\n",
    "    def __init__(self, channels_in, num_actions):\n",
    "        super(CnnDQN, self).__init__()\n",
    "        \n",
    "        self.channels_in = channels_in\n",
    "        self.num_actions = num_actions\n",
    "        self.feature_size = 1152\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(channels_in, 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride = 3)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.feature_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, self.num_actions)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "       \n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def act(state, epsilon):\n",
    "        if random.random() > epsilon:\n",
    "            #state   = Variable(torch.FloatTensor(np.float32(state)).unsqueeze(0), volatile=True)\n",
    "            q_value = self.forward(state)\n",
    "            action  = q_value.max(1)[1].item()\n",
    "        else:\n",
    "            n = random.randrange(self.num_actions)\n",
    "            action = random.randrange(env.action_space.n)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set device to GPU_indx if GPU is avaliable\n",
    "GPU_indx = 0\n",
    "device = torch.device(GPU_indx if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not needed anymore - Outdated, can straight find loss and backward pass\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "Variable = lambda *args, **kwargs: autograd.Variable(*args, **kwargs).cuda() if USE_CUDA else autograd.Variable(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_input = 3\n",
    "num_actions = 3\n",
    "model = CnnDQN(channels_input, num_actions).to(device) # (210, 160, 3) , (6)\n",
    "\n",
    "lr = 1e-5\n",
    "    \n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "replay_initial = 10000\n",
    "replay_buffer = ReplayBuffer(100000)\n",
    "\n",
    "# Frame:\n",
    "start = 1\n",
    "total_frames = 2\n",
    "\n",
    "# start:\n",
    "game = SnakeGameAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_start = 1.0\n",
    "epsilon_final = 0.01\n",
    "epsilon_decay = 30000\n",
    "\n",
    "epsilon_by_frame = lambda frame_idx: epsilon_final + (epsilon_start - epsilon_final) * math.exp(-1. * frame_idx / epsilon_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([epsilon_by_frame(i) for i in range(1000000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Final Score 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "episode_reward = 0\n",
    "out = 0\n",
    "\n",
    "#game = SnakeGameAI()\n",
    "move = np.zeros(3).astype(np.int)\n",
    "move = move.tolist()\n",
    "_, _, _, array3D = game.play_step(move) # No.0\n",
    "for curr_frame in range(start, total_frames):\n",
    "    # later all this will be move into train_epoch function\n",
    "    state = torch.tensor(array3D.transpose((2,1,0))).unsqueeze(0) # Getting image in 4D Tensor\n",
    "    #print(state.shape)\n",
    "    \n",
    "    model.train()    # Start training\n",
    "    move = np.zeros(3).astype(np.int)\n",
    "    \n",
    "    \n",
    "    epsilon = epsilon_by_frame(curr_frame) # No. 1\n",
    "    if random.random() > epsilon:\n",
    "        #state   = Variable(torch.FloatTensor(np.float32(state)).unsqueeze(0), volatile=True)\n",
    "        state = state.float()\n",
    "        q_value = model(state.to(device))\n",
    "        action  = q_value.max(1)[1].data[0]\n",
    "    else:\n",
    "        action = random.randrange(num_actions)\n",
    "\n",
    "    move[action] = 1\n",
    "    move = move.tolist()\n",
    "    \n",
    "    reward, game_over, score, array3D = game.play_step(move) # No.2\n",
    "    next_state = torch.tensor(array3D.transpose((2,1,0))).unsqueeze(0) # Getting image in 4D Tensor\n",
    "    \n",
    "    state = next_state\n",
    "    episode_reward += reward\n",
    "    \n",
    "    # Continue .... if game_over:.....\n",
    "    \n",
    "    # hold while waiting your command:\n",
    "    out = input()\n",
    "    if (int(out) == 1):\n",
    "        break\n",
    "game.reset()\n",
    "print('Final Score', score)\n",
    "pygame.display.quit() \n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0]\n",
      "torch.Size([1, 3, 120, 180]) torch.Size([1, 3, 120, 180])\n"
     ]
    }
   ],
   "source": [
    "state = state.float()\n",
    "q_value = model(state.to(device))\n",
    "action  = q_value.max(1)[1].data[0]\n",
    "\n",
    "mv = np.zeros(3).astype(int)\n",
    "mv[action] = 1\n",
    "mv = mv.tolist()\n",
    "print(mv)\n",
    "\n",
    "print(state.shape, next_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20a04f887f0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = nn.Softmax(dim=1)\n",
    "m(q_value)\n",
    "\n",
    "img = state.cpu().detach().numpy()\n",
    "img = img.squeeze(0).transpose((1,2,0))\n",
    "plt.imshow(img/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames = 10000\n",
    "batch_size = 32\n",
    "gamma      = 0.99\n",
    "\n",
    "losses = []\n",
    "all_rewards = []\n",
    "episode_reward = 0\n",
    "\n",
    "state = env.reset() # No.0\n",
    "# No.0 - play 1st frame\n",
    "# No.1 - get action from CNN\n",
    "# No.2 insert action into the game - get all things -> next state\n",
    "# No.3 push into buffer\n",
    "# No.4 current is next state\n",
    "\n",
    "for frame_idx in range(1, num_frames + 1):\n",
    "    epsilon = epsilon_by_frame(frame_idx) \n",
    "    action = model.act(state, epsilon) # No.1 - state & epsilon(random) to get action (random or learnt)\n",
    "    \n",
    "    next_state, reward, done, _ = env.step(action) # No.2\n",
    "    replay_buffer.push(state, action, reward, next_state, done) # No.3\n",
    "    \n",
    "    state = next_state # No.4\n",
    "    episode_reward += reward\n",
    "    \n",
    "    if done:\n",
    "        state = env.reset()\n",
    "        all_rewards.append(episode_reward)\n",
    "        episode_reward = 0\n",
    "        \n",
    "    if len(replay_buffer) > batch_size:\n",
    "        loss = compute_td_loss(batch_size)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "    if frame_idx % 200 == 0:\n",
    "        plot(frame_idx, all_rewards, losses)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#    x = state.float() # Tensor float (4D image)\n",
    "\n",
    "    q = model(x.to(device)) # Getting Q value / table (in softmax)\n",
    "\n",
    "    action = q.max(1)[1].data[0] # Taking max value\n",
    "    print(action)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
